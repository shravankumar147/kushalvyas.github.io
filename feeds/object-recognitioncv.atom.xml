<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>BitsMakeMeCrazy Kushal Vyas's Blog</title><link href="http://kushalvyas.github.io/" rel="alternate"></link><link href="http://kushalvyas.github.io/feeds/object-recognitioncv.atom.xml" rel="self"></link><id>http://kushalvyas.github.io/</id><updated>2016-07-13T00:00:00+05:30</updated><entry><title>Simple Object RecognitionÂ techniques</title><link href="http://kushalvyas.github.io/Obj_CV.html" rel="alternate"></link><updated>2016-07-13T00:00:00+05:30</updated><author><name>Kushal Vyas</name></author><id>tag:kushalvyas.github.io,2016-07-13:Obj_CV.html</id><summary type="html">&lt;p&gt;Object recognition is one of the hot topics in computer vision. Particularly, of much significance, it has various applications in robotics, identification, interpretation and such image oriented&amp;nbsp;tasks. &lt;/p&gt;
&lt;p&gt;One can ramify between Object recognition into 4 major subsets such as&amp;nbsp;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Template based approach&lt;/strong&gt; : We take the object and match the object with distribution pattern of intensities. It&amp;#8217;s quite exhaustive is not invariant to geometric transformations inside search image
    Eg: Template Matching . However, this isint much&amp;nbsp;sturdy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Geometric approach&lt;/strong&gt; : Recognize the object on basis of edges, corners, angles. Then we create a one 2  one match and then make a transformation that handles rotation, scaling, etx.&lt;br /&gt;
    Eg: Matching w.r.t positioning of objects. Classifying&amp;nbsp;patterns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph based approach&lt;/strong&gt; : we match similar types of structures. Encode the relationship between structures rather than the geometry of the&amp;nbsp;figure.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bag of Visual Words&lt;/strong&gt; : I will cover Bag of Words in a seperate post &lt;a href="http://kushalvyas.github.io/BOV.html"&gt;Bag of Words&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;I&amp;#8217;ll be going through a couple of common techniques. Firstly I&amp;#8217;ll introduce template matching and in the follow, using probabilistic recognition , then moving on to Machine learning applications such as using &lt;span class="caps"&gt;BOW&lt;/span&gt; models coupled with &lt;span class="caps"&gt;SVM&lt;/span&gt; , or feature extrapolation and recognition using neural&amp;nbsp;nets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Template based aproach&lt;/strong&gt; 
Well, there are  a few contentions i;d like to make when we use this approach. Shape based approach is not the key or the best method for recognition. But , in industry, all methods have their perks. Say we have an industry converyor belt that is suppossed to carry only boxes or T- Joints or anything so simply extrapolable and uniform that it is feasible to use shape matching rather than going for complex approaches like using nets, or using &lt;span class="caps"&gt;SVM&lt;/span&gt; along with bag of words. Then I&amp;#8217;d say, template matching or shape based matching is the best bet in terms of accuracy as well as&amp;nbsp;speed. &lt;/p&gt;
&lt;p&gt;Lets dive a little deeper in the aforementioned topic.
I&amp;#8217;ll be using template matching as an example to explain how Shape based matching works. Consider two images. The template image (T) and the actual image (I). We say that we want to find the location / occurence of template inside the actual&amp;nbsp;image.&lt;/p&gt;
&lt;p&gt;In simple words I can say, return True, iff $T \subseteq I$. But life aint so simple. In reality, every pixel needs to be iterated over and checked. It can be said that the a template is belonging to a particular image iff, all pixels match exactly. i.e. the sum of ( Absolute Difference between every pixel must be&amp;nbsp;zero).&lt;/p&gt;
&lt;p&gt;$$&lt;span class="caps"&gt;SAD&lt;/span&gt;(x, y) = \sum_{i=0}^{T_{\text{rows}}}\sum_{j=0}^{T_{\text{cols}}} {\text{Diff}(x+i,&amp;nbsp;y+j,i,j)}$$&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s how the above formula&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;$&lt;span class="caps"&gt;SAD&lt;/span&gt;$ : sum of absolute differences.
$&lt;span class="caps"&gt;SAD&lt;/span&gt; (x, y)$ : the &lt;span class="caps"&gt;SAD&lt;/span&gt; of a particular pixel location in the actual Image&amp;nbsp;$I$ &lt;/p&gt;
&lt;p&gt;Each pixel in $I$ can be represented using $(x, y)$. It has an intensity, or color value expresed as&amp;nbsp;$Intensity(I(x,y))$.&lt;/p&gt;
&lt;p&gt;Now, a pixel in template image $T(p,q)$ will have intensity as&amp;nbsp;$Intensity(T(p,q))$.&lt;/p&gt;
&lt;p&gt;A search window is created that is of the size of template image. The window is then slid over the actual Image I and every time &lt;span class="caps"&gt;SAD&lt;/span&gt; is computed. For checking single occurence of template the iterations can be stopped once &lt;span class="caps"&gt;SAD&lt;/span&gt; is $0$, or else it can be continued until the end of $I$ is&amp;nbsp;reached. &lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll be implementing the algorithm using opencv ,&amp;nbsp;python &lt;/p&gt;
&lt;p&gt;[gist:id=c151fd726bb3d439b721b264f3d50843]&lt;/p&gt;
&lt;p&gt;Take a look at $line 14$, it states &lt;code&gt;cv2.TM_SQDIFF&lt;/code&gt; parameter in matchTemplate(). Opencv&amp;#8217;s rendition for &lt;span class="caps"&gt;SAD&lt;/span&gt; can be delineated as : 
$$R(x, y) = \sum_{i, j}\ {(\text{T}(i,j) - \text{I}(x+i,&amp;nbsp;y+j))^2}$$&lt;/p&gt;
&lt;p&gt;And here is the output ! We will search a pair of glares from this paraphenalia
&lt;center&gt;
&lt;img alt="crop" src="http://kushalvyas.github.io/images/tempCrop.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="original" src="http://kushalvyas.github.io/images/optemplate.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Okay, so template matching can be established using the opencv api. Its&amp;#8217; quite simple to implement in plain ol c++ as well. Not a biggie.  We&amp;#8217;ll use the helper functions for image reading , accessing pixel value, etc. but the rest can be quite easily implemented using a bunch of &lt;code&gt;for loops&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[gist:id=0667c6a249f3397ee7de1db0cf04555d]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You can find my remaining code on &lt;a href="https://github.com/kushalvyas/ObjectDetectionPython"&gt;Github&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; remaining posts on other approaches coming soon&amp;nbsp;&amp;#8230; &lt;/strong&gt;&lt;/p&gt;</summary><category term="ObjectRecognition"></category><category term="CV"></category></entry></feed>