<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>BitsMakeMeCrazy | Kushal Vyas's Blog</title><link href="http://kushalvyas.github.io/" rel="alternate"></link><link href="http://kushalvyas.github.io/feeds/object-recognitioncv.atom.xml" rel="self"></link><id>http://kushalvyas.github.io/</id><updated>2016-07-13T00:00:00+05:30</updated><entry><title>Simple Object RecognitionÂ techniques</title><link href="http://kushalvyas.github.io/Obj_CV.html" rel="alternate"></link><updated>2016-07-13T00:00:00+05:30</updated><author><name>Kushal Vyas</name></author><id>tag:kushalvyas.github.io,2016-07-13:Obj_CV.html</id><summary type="html">&lt;p&gt;Object recognition is one of the hot topics in computer vision. Particularly, of much significance, it has various applications in robotics, identification, interpretation and such image oriented&amp;nbsp;tasks. &lt;/p&gt;
&lt;p&gt;One can ramify between Object recognition into 4 major subsets such as&amp;nbsp;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Template based approach&lt;/strong&gt; : We take the object and match the object with distribution pattern of intensities. It&amp;#8217;s quite exhaustive is not invariant to geometric transformations inside search image
    Eg: Template Matching . However, this isint much&amp;nbsp;sturdy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Geometric approach&lt;/strong&gt; : Recognize the object on basis of edges, corners, angles. Then we create a one 2  one match and then make a transformation that handles rotation, scaling, etx.&lt;br /&gt;
    Eg: Matching w.r.t positioning of objects. Classifying&amp;nbsp;patterns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph based approach&lt;/strong&gt; : we match similar types of structures. Encode the relationship between structures rather than the geometry of the&amp;nbsp;figure.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bag of Visual Words&lt;/strong&gt; : I will cover Bag of Words in a seperate post &lt;a href="http://kushalvyas.github.io/BOV.html"&gt;Bag of Words&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;I&amp;#8217;ll be going through a couple of common techniques. Firstly I&amp;#8217;ll introduce template matching and in the follow, using probabilistic recognition , then moving on to Machine learning applications such as using &lt;span class="caps"&gt;BOW&lt;/span&gt; models coupled with &lt;span class="caps"&gt;SVM&lt;/span&gt; , or feature extrapolation and recognition using neural&amp;nbsp;nets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Template based aproach&lt;/strong&gt; 
Well, there are  a few contentions i;d like to make when we use this approach. Shape based approach is not the key or the best method for recognition. But , in industry, all methods have their perks. Say we have an industry converyor belt that is suppossed to carry only boxes or T- Joints or anything so simply extrapolable and uniform that it is feasible to use shape matching rather than going for complex approaches like using nets, or using &lt;span class="caps"&gt;SVM&lt;/span&gt; along with bag of words. Then I&amp;#8217;d say, template matching or shape based matching is the best bet in terms of accuracy as well as&amp;nbsp;speed. &lt;/p&gt;
&lt;p&gt;Lets dive a little deeper in the aforementioned topic.
I&amp;#8217;ll be using template matching as an example to explain how Shape based matching works. Consider two images. The template image (T) and the actual image (I). We say that we want to find the location / occurence of template inside the actual&amp;nbsp;image.&lt;/p&gt;
&lt;p&gt;In simple words I can say, return True, iff &lt;span class="math"&gt;\(T \subseteq I\)&lt;/span&gt;. But life aint so simple. In reality, every pixel needs to be iterated over and checked. It can be said that the a template is belonging to a particular image iff, all pixels match exactly. i.e. the sum of ( Absolute Difference between every pixel must be&amp;nbsp;zero).&lt;/p&gt;
&lt;div class="math"&gt;$$SAD(x, y) = \sum_{i=0}^{T_{\text{rows}}}\sum_{j=0}^{T_{\text{cols}}} {\text{Diff}(x+i, y+j,i,j)}$$&lt;/div&gt;
&lt;p&gt;Here&amp;#8217;s how the above formula&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(SAD\)&lt;/span&gt; : sum of absolute differences.
&lt;span class="math"&gt;\(SAD (x, y)\)&lt;/span&gt; : the &lt;span class="caps"&gt;SAD&lt;/span&gt; of a particular pixel location in the actual Image &lt;span class="math"&gt;\(I\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;Each pixel in &lt;span class="math"&gt;\(I\)&lt;/span&gt; can be represented using &lt;span class="math"&gt;\((x, y)\)&lt;/span&gt;. It has an intensity, or color value expresed as &lt;span class="math"&gt;\(Intensity(I(x,y))\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now, a pixel in template image &lt;span class="math"&gt;\(T(p,q)\)&lt;/span&gt; will have intensity as &lt;span class="math"&gt;\(Intensity(T(p,q))\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A search window is created that is of the size of template image. The window is then slid over the actual Image I and every time &lt;span class="caps"&gt;SAD&lt;/span&gt; is computed. For checking single occurence of template the iterations can be stopped once &lt;span class="caps"&gt;SAD&lt;/span&gt; is &lt;span class="math"&gt;\(0\)&lt;/span&gt;, or else it can be continued until the end of &lt;span class="math"&gt;\(I\)&lt;/span&gt; is&amp;nbsp;reached. &lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll be implementing the algorithm using opencv ,&amp;nbsp;python &lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/c151fd726bb3d439b721b264f3d50843.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;"""
Template matching using opencv

Run : python file.py &lt;templateImage&gt; &lt;actualImage&gt;


"""

import sys, cv2
import numpy as np

def main(template, actualImage):
	tImage = cv2.imread(template, 0)
	aImage = cv2.imread(actualImage)
	aCopy = aImage.copy()
	aImage = cv2.cvtColor(aImage, cv2.COLOR_BGR2GRAY)
	th, tw = tImage.shape[:2]

	match = cv2.matchTemplate(aImage, tImage, cv2.TM_SQDIFF)
	minmaxlocs = cv2.minMaxLoc(match)
	topcorner = minmaxlocs[-2]
	bottomcorner=  (topcorner[0] + tw, topcorner[1]+th)
	cv2.rectangle(aCopy, topcorner, bottomcorner, (0, 0, 255), 2)

	cv2.imshow("actual Iamge", aCopy)
	cv2.waitKey()


if __name__ == '__main__':
	args = sys.argv[1:]
	print args
	if (len(args) is not 2):
		print "Please pass cmd args for template and actual image"
		sys.exit(-1)

	main(args[0], args[1])&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;Take a look at &lt;span class="math"&gt;\(line 14\)&lt;/span&gt;, it states &lt;code&gt;cv2.TM_SQDIFF&lt;/code&gt; parameter in matchTemplate(). Opencv&amp;#8217;s rendition for &lt;span class="caps"&gt;SAD&lt;/span&gt; can be delineated as&amp;nbsp;: 
&lt;/p&gt;
&lt;div class="math"&gt;$$R(x, y) = \sum_{i, j}\ {(\text{T}(i,j) - \text{I}(x+i, y+j))^2}$$&lt;/div&gt;
&lt;p&gt;And here is the output ! We will search a pair of glares from this paraphenalia
&lt;center&gt;
&lt;img alt="crop" src="http://kushalvyas.github.io/images/tempCrop.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="original" src="http://kushalvyas.github.io/images/optemplate.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Okay, so template matching can be established using the opencv api. Its&amp;#8217; quite simple to implement in plain ol c++ as well. Not a biggie.  We&amp;#8217;ll use the helper functions for image reading , accessing pixel value, etc. but the rest can be quite easily implemented using a bunch of &lt;code&gt;for loops&lt;/code&gt;&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/0667c6a249f3397ee7de1db0cf04555d.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;/*
Author : Kushal Vyas
Code for template matching as implemented by opencv.

*/
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/opencv.hpp"
#include "iostream"
#include "cmath"

using namespace std;
using namespace cv;

int main(){
	cout&lt;&lt;"Template matching \n";
	Mat tImage, aImage, aCopy;
	tImage = imread("tempCrop.jpg",0);
	aImage = imread("temA1.jpg",0);
	aCopy = imread("temA1.jpg");


	// performing template matching using SAD method
	Size Tsize, Isize ;
	Tsize = tImage.size();
	Isize = aImage.size();

	
	long int minSAD = 999999999999, SAD=0;
	int xloc=0, yloc=0, sadloc=0;
	// loop through the actual image
	int a_i, a_j;
	for (a_i =0; a_i &lt; Isize.height - Tsize.height; a_i++){
		for (a_j=0; a_j &lt; Isize.width - Tsize.width; a_j++){
			SAD = 0;

			// check every pixel of actual image with the template image
			// loop through the template image
			for(int t_j=0; t_j &lt; Tsize.width; t_j++){
				for(int t_i=0; t_i &lt; Tsize.height; t_i++){
					uchar aT = aImage.at&lt;uchar&gt;( a_i+t_i, a_j+t_j );
					uchar tT = tImage.at&lt;uchar&gt;(t_i, t_j);
					SAD += pow(abs(int(aT) - int(tT)),2);
				}
			}
			// cout &lt;&lt;"SASD sis "&lt;&lt;SAD&lt;&lt;endl; 
			// save the best found position
			if(minSAD &gt; SAD ){
				cout &lt;&lt;" SAD "&lt;&lt; SAD&lt;&lt;endl;
				minSAD = SAD;
				yloc = a_i;
				xloc = a_j;
				sadloc = SAD;
			}
		}
	}

	cout&lt;&lt;"Template size"&lt;&lt;Tsize&lt;&lt;endl;
	cout&lt;&lt;"Image size"&lt;&lt;Isize&lt;&lt;endl;

	cout&lt;&lt;a_i&lt;&lt;" "&lt;&lt;a_j&lt;&lt;endl;

	cout&lt;&lt;xloc&lt;&lt;","&lt;&lt;yloc&lt;&lt;" SAD is "&lt;&lt;sadloc&lt;&lt;endl;

	// create a rectangle to demarkate the region
	rectangle(aCopy, Point(xloc, yloc), Point(xloc+Tsize.width, yloc+Tsize.height), Scalar(0,0,255), 2);

	// imshow("Template image", tImage);
	imshow("Actual image", aImage);
	imshow("Matched Image", aCopy);
	waitKey();
	destroyAllWindows();

	return 0;
}&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;You can find my remaining code on &lt;a href="https://github.com/kushalvyas/ObjectDetectionPython"&gt;Github&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; remaining posts on other approaches coming soon&amp;nbsp;&amp;#8230; &lt;/strong&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="ObjectRecognition"></category><category term="CV"></category></entry></feed>